{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\\Lib\\site-packages\\tensorflow_datasets\\core\\shuffle.py \\\n",
    "\\# import resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install protobuf==3.19.6 tensorflow-metadata==1.10.0 tensorflow_datasets==4.6.0 tensorflow-gpu==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tf_data(Train_size = 32, Test_size = 16, img_size = 224, random_ratio = 0.1):\n",
    "    (train_ds, test_ds), ds_info = tfds.load(\n",
    "        'cifar10',\n",
    "        split=['train', 'test'],\n",
    "        as_supervised=True,\n",
    "        with_info=True\n",
    "    )\n",
    "    \n",
    "    def preprocess(image, label):\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = tf.image.resize(image, (img_size, img_size))\n",
    "        return image, label\n",
    "    \n",
    "    def augment(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image, random_ratio)\n",
    "        image = tf.image.random_contrast(image, 1 - random_ratio, 1 + random_ratio)\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    train_ds = (train_ds\n",
    "                .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "                .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "                .shuffle(10000)\n",
    "                .batch(Train_size)\n",
    "                .prefetch(AUTOTUNE))\n",
    "    \n",
    "    test_ds = (test_ds\n",
    "               .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "               .batch(Test_size)\n",
    "               .prefetch(AUTOTUNE))\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = prepare_tf_data(img_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vit import VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class PatchEmbed(layers.Layer):\n",
    "    def __init__(self, patch_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = layers.Conv2D(embed_dim, patch_size, strides=patch_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.proj(x)\n",
    "        return tf.reshape(x, [tf.shape(x)[0], -1, tf.shape(x)[-1]])\n",
    "\n",
    "class VisionTransformer(keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_shape,\n",
    "        patch_size,\n",
    "        num_classes,\n",
    "        embed_dim,\n",
    "        depth,\n",
    "        num_heads,\n",
    "        mlp_ratio=4,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
    "        self.patch_embed = PatchEmbed(patch_size, embed_dim)\n",
    "        \n",
    "        self.cls_token = self.add_weight(\n",
    "            \"cls_token\", shape=[1, 1, embed_dim],\n",
    "            initializer=\"zeros\", trainable=True\n",
    "        )\n",
    "        self.pos_embed = self.add_weight(\n",
    "            \"pos_embed\", shape=[1, num_patches + 1, embed_dim],\n",
    "            initializer=\"zeros\", trainable=True\n",
    "        )\n",
    "        \n",
    "        # self.blocks = [\n",
    "        #     TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n",
    "        #     for _ in range(depth)\n",
    "        # ]\n",
    "\n",
    "        self.blocks = tf.keras.Sequential([\n",
    "            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.head = layers.Dense(num_classes)\n",
    "        \n",
    "    def call(self, x):\n",
    "        B = tf.shape(x)[0]\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        cls_tokens = tf.repeat(self.cls_token, B, axis=0)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        x = x + self.pos_embed\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        x = self.head(x[:, 0])\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.attn = layers.MultiHeadAttention(num_heads, dim//num_heads)\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(int(dim * mlp_ratio)),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dense(dim)\n",
    "        ])\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 32 \n",
    "# patch_size = 8  \n",
    "# num_layers = 6 \n",
    "# num_heads = 6   \n",
    "# hidden_dim = 384\n",
    "# mlp_dim = 1536   \n",
    "# num_classes = 10 \n",
    "# dropout = 0.08   \n",
    "# attention_dropout = 0.08 \n",
    "\n",
    "vit = VisionTransformer(\n",
    "    input_shape=(32, 32, 3),\n",
    "    patch_size=8,\n",
    "    num_classes=10,\n",
    "    embed_dim=384,\n",
    "    depth=6,\n",
    "    num_heads=6,\n",
    "    mlp_ratio=4,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# vit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-4\n",
    "decay_steps = 5000\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps\n",
    "# )\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=0.9,  \n",
    "    staircase=True   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "vit.compile(\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay=0.0001\n",
    "),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# vit.compile(\n",
    "#     optimizer=tf.keras.optimizers.AdamW(\n",
    "#         learning_rate=lr_schedule,\n",
    "#         weight_decay=0.0001\n",
    "#     ),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#     metrics=['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'vit_cifar10_best',  \n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs/vit_cifar10')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.6190 - accuracy: 0.4182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1272s 811ms/step - loss: 1.6190 - accuracy: 0.4182 - val_loss: 1.5373 - val_accuracy: 0.4404\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5042 - accuracy: 0.4597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1213s 776ms/step - loss: 1.5042 - accuracy: 0.4597 - val_loss: 1.4750 - val_accuracy: 0.4651\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.4716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1204s 770ms/step - loss: 1.4648 - accuracy: 0.4716 - val_loss: 1.4330 - val_accuracy: 0.4764\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 1131s 723ms/step - loss: 1.4426 - accuracy: 0.4819 - val_loss: 1.4557 - val_accuracy: 0.4738\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4179 - accuracy: 0.4889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1148s 734ms/step - loss: 1.4179 - accuracy: 0.4889 - val_loss: 1.4018 - val_accuracy: 0.4977\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4044 - accuracy: 0.4964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1217s 778ms/step - loss: 1.4044 - accuracy: 0.4964 - val_loss: 1.3734 - val_accuracy: 0.5050\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.5027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1185s 758ms/step - loss: 1.3902 - accuracy: 0.5027 - val_loss: 1.3699 - val_accuracy: 0.5141\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 1119s 715ms/step - loss: 1.3816 - accuracy: 0.5051 - val_loss: 1.4222 - val_accuracy: 0.4961\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 1145s 733ms/step - loss: 1.3794 - accuracy: 0.5093 - val_loss: 1.3887 - val_accuracy: 0.5058\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3732 - accuracy: 0.5100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, layer_normalization_91_layer_call_fn, layer_normalization_91_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vit_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1173s 750ms/step - loss: 1.3732 - accuracy: 0.5100 - val_loss: 1.3506 - val_accuracy: 0.5164\n"
     ]
    }
   ],
   "source": [
    "history = vit.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = vit.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.layers.Layer):\n",
    "   def __init__(self, filters, strides=1):\n",
    "       super().__init__()\n",
    "       self.conv1 = tf.keras.layers.Conv2D(filters, 3, strides=strides, padding='same')\n",
    "       self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "       self.conv2 = tf.keras.layers.Conv2D(filters, 3, padding='same') \n",
    "       self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "       if strides != 1:\n",
    "           self.downsample = tf.keras.Sequential([\n",
    "               tf.keras.layers.Conv2D(filters, 1, strides=strides),\n",
    "               tf.keras.layers.BatchNormalization()\n",
    "           ])\n",
    "       else:\n",
    "           self.downsample = None\n",
    "\n",
    "   def call(self, inputs):\n",
    "       identity = inputs\n",
    "       \n",
    "       x = self.conv1(inputs)\n",
    "       x = self.bn1(x)\n",
    "       x = tf.nn.relu(x)\n",
    "       \n",
    "       x = self.conv2(x)\n",
    "       x = self.bn2(x)\n",
    "\n",
    "       if self.downsample is not None:\n",
    "           identity = self.downsample(inputs)\n",
    "           \n",
    "       x += identity\n",
    "       return tf.nn.relu(x)\n",
    "\n",
    "class ResNet18_v2(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, 7, strides=2, padding='same')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(3, strides=2, padding='same')\n",
    "        \n",
    "        # 直接使用多个 ResBlock 实例，不用 Sequential\n",
    "        self.blocks1 = [ResBlock(64) for _ in range(2)]\n",
    "        self.blocks2 = [ResBlock(128, strides=2)] + [ResBlock(128) for _ in range(1)]\n",
    "        self.blocks3 = [ResBlock(256, strides=2)] + [ResBlock(256) for _ in range(1)]\n",
    "        self.blocks4 = [ResBlock(512, strides=2)] + [ResBlock(512) for _ in range(1)]\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(num_classes)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        for block in self.blocks1:\n",
    "            x = block(x)\n",
    "        for block in self.blocks2:\n",
    "            x = block(x)\n",
    "        for block in self.blocks3:\n",
    "            x = block(x)\n",
    "        for block in self.blocks4:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.7119 - accuracy: 0.4023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 463s 295ms/step - loss: 1.7119 - accuracy: 0.4023 - val_loss: 1.4253 - val_accuracy: 0.4824\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.5338"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 772s 494ms/step - loss: 1.3097 - accuracy: 0.5338 - val_loss: 1.3035 - val_accuracy: 0.5199\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1391 - accuracy: 0.5939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 755s 483ms/step - loss: 1.1391 - accuracy: 0.5939 - val_loss: 1.2194 - val_accuracy: 0.5745\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.6460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 756s 484ms/step - loss: 1.0048 - accuracy: 0.6460 - val_loss: 1.0689 - val_accuracy: 0.6232\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 755s 483ms/step - loss: 0.9164 - accuracy: 0.6781 - val_loss: 1.2214 - val_accuracy: 0.5795\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.7038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 766s 490ms/step - loss: 0.8533 - accuracy: 0.7038 - val_loss: 1.0353 - val_accuracy: 0.6389\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7979 - accuracy: 0.7248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 770s 493ms/step - loss: 0.7979 - accuracy: 0.7248 - val_loss: 0.9963 - val_accuracy: 0.6522\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.7433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 742s 474ms/step - loss: 0.7533 - accuracy: 0.7433 - val_loss: 0.9700 - val_accuracy: 0.6643\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 746s 477ms/step - loss: 0.7285 - accuracy: 0.7517 - val_loss: 0.9641 - val_accuracy: 0.6616\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6984 - accuracy: 0.7665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 753s 482ms/step - loss: 0.6984 - accuracy: 0.7665 - val_loss: 0.8348 - val_accuracy: 0.7140\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 763s 488ms/step - loss: 0.6779 - accuracy: 0.7754 - val_loss: 0.9168 - val_accuracy: 0.6842\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 727s 465ms/step - loss: 0.6733 - accuracy: 0.7796 - val_loss: 1.0357 - val_accuracy: 0.6486\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 726s 465ms/step - loss: 0.6743 - accuracy: 0.7828 - val_loss: 0.9455 - val_accuracy: 0.6829\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.7875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, conv2d_105_layer_call_fn, conv2d_105_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_106_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: res_cifar10_best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 715s 458ms/step - loss: 0.6560 - accuracy: 0.7875 - val_loss: 0.7653 - val_accuracy: 0.7467\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 763s 488ms/step - loss: 0.6523 - accuracy: 0.7896 - val_loss: 0.8425 - val_accuracy: 0.7156\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 767s 490ms/step - loss: 0.6525 - accuracy: 0.7890 - val_loss: 0.8307 - val_accuracy: 0.7229\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 747s 478ms/step - loss: 0.6366 - accuracy: 0.7957 - val_loss: 0.8373 - val_accuracy: 0.7186\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 750s 480ms/step - loss: 0.6419 - accuracy: 0.7949 - val_loss: 0.9938 - val_accuracy: 0.6642\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 752s 481ms/step - loss: 0.6404 - accuracy: 0.7959 - val_loss: 0.8165 - val_accuracy: 0.7247\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 842s 539ms/step - loss: 0.6341 - accuracy: 0.7992 - val_loss: 1.0705 - val_accuracy: 0.6330\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 756s 484ms/step - loss: 0.6355 - accuracy: 0.7984 - val_loss: 0.9245 - val_accuracy: 0.6838\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 764s 489ms/step - loss: 0.6444 - accuracy: 0.7960 - val_loss: 1.0165 - val_accuracy: 0.6643\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 753s 482ms/step - loss: 0.6467 - accuracy: 0.7954 - val_loss: 0.9121 - val_accuracy: 0.6945\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 757s 484ms/step - loss: 0.6518 - accuracy: 0.7975 - val_loss: 0.9864 - val_accuracy: 0.6694\n"
     ]
    }
   ],
   "source": [
    "res = ResNet18_v2(num_classes=10)\n",
    "\n",
    "initial_learning_rate = 5e-5\n",
    "decay_steps = 5000\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps\n",
    "# )\n",
    "\n",
    "lr_schedule_res = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=0.9,  \n",
    "    staircase=True  \n",
    ")\n",
    "\n",
    "res.compile(\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule_res,\n",
    "    weight_decay=0.0001\n",
    "),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks_res = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'res_cifar10_best',  \n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs/res_cifar10')\n",
    "]\n",
    "\n",
    "history_res = res.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks_res\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
